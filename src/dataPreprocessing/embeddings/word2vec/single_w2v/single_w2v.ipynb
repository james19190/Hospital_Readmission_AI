{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Word2Vec\n",
    "\n",
    "- singular w2v embedding for diagnosis, procedures, and drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pickle\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sequences for Word2Vec:\n",
      "['d_572', 'd_789', 'd_571', 'd_070', 'd_496', 'd_296', 'd_309', 'pcs_549', 'p_NACLFLUSH', 'p_SPIR25', 'p_RALT400', 'p_ALBU17H', 'p_FURO20', 'p_MICROK10', 'p_NICO14P', 'p_HEPA5I', 'p_SPIR25', 'p_IPRA2H', 'p_INFL0.5LF', 'p_TRUV200/300', 'p_FURO40', 'p_APAP500']\n",
      "['d_070', 'd_789', 'd_287', 'd_276', 'd_496', 'd_571', 'd_305', 'pcs_549', 'p_BACTDS', 'p_TIOT', 'p_RIFA550', 'p_APAP500', 'p_ALBU25', 'p_NACLFLUSH', 'p_RALT400', 'p_HEPA5I', 'p_TRUV200/300', 'p_CAL1250', 'p_FURO40', 'p_INFL0.5LF', 'p_FURO20', 'p_ALBU17H', 'p_LACT30L']\n",
      "['d_458', 'd_070', 'd_799', 'd_276', 'd_789', 'd_276', 'd_305', 'd_496', 'd_296', 'd_571', 'p_TRAM50', 'p_TIOT', 'p_TRUV200/300', 'p_ALBU25', 'p_TRAM50', 'p_FLUT110HFA', 'p_RIFA550', 'p_SENN187', 'p_INFL0.5LF', 'p_BISA5', 'p_ALBU3H', 'p_BISA10R', 'p_CALC500', 'p_ALBU17H', 'p_RALT400', 'p_DOCU100L', 'p_DOCU100L', 'p_SENN187', 'p_NACLFLUSH', 'p_BISA5', 'p_BISA10R', 'p_LACT30L', 'p_ALBU25', 'p_HEPA5I']\n",
      "['d_571', 'd_486', 'd_789', 'd_572', 'd_599', 'd_263', 'd_276', 'd_511', 'd_571', 'd_276', 'd_303', 'd_564', 'd_281', 'd_300', 'pcs_549', 'pcs_549', 'p_LORA2I', 'p_SENN187', 'p_FOLI1', 'p_MAG2PM', 'p_LORA1', 'p_LORA5', 'p_LORA1', 'p_ONDAN4I', 'p_FURO20', 'p_NS500', 'p_OXYC5', 'p_NEUT', 'p_DOCU100', 'p_LORA2I', 'p_CIPR250', 'p_HEPA5I', 'p_LORA2I', 'p_OXYC5', 'p_LIDO5T', 'p_ACET325', 'p_POTA20', 'p_PHYT5', 'p_MVI', 'p_HEPA5I', 'p_SW50', 'p_MAG2PM', 'p_SW50', 'p_MAG2PM', 'p_CIPR500', 'p_LORA2I', 'p_POTA20', 'p_THIA100', 'p_NS500', 'p_ALBU25', 'p_LORA2I', 'p_LORA5', 'p_NACLFLUSH', 'p_NS451000', 'p_LORA2I', 'p_LORA2I', 'p_MORP2I', 'p_THIAM100I', 'p_MVI10I', 'p_THIAM100I', 'p_NS1000', 'p_FOLI5I', 'p_NEUT', 'p_MORP4I', 'p_NICO14P', 'p_LORA2I', 'p_LORA5', 'p_SENN187', 'p_LORA2I', 'p_LORA1', 'p_THIA100', 'p_FOLI1', 'p_DOCU100']\n",
      "['d_571', 'd_995', 'd_789', 'd_276', 'd_599', 'd_511', 'd_571', 'd_303', 'd_305', 'pcs_549', 'pcs_549', 'pcs_549', 'p_HEPA5I', 'p_NICO14P', 'p_PHYT5', 'p_ALBU25', 'p_ALBU25', 'p_OXYC5', 'p_FOLI1', 'p_OXYC5', 'p_HEPA5I', 'p_ACET20/4I', 'p_LIDO5T', 'p_MVI', 'p_SPIR25', 'p_OXYC5', 'p_MAG2PM', 'p_SARNL', 'p_KAYE15L', 'p_MORP2I', 'p_NS500', 'p_PHYT5', 'p_PHYT5', 'p_FRBD50', 'p_CEFX2F', 'p_LACT30L', 'p_NACLFLUSH', 'p_PHYT10I', 'p_D545NS1000', 'p_ALBU25', 'p_HEPA5I', 'p_OXYC5', 'p_HEPBASE', 'p_HEPPREMIX', 'p_ONDAN4I', 'p_THIA100']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load data\n",
    "X_filePath = '../../../data/preprocessed_X_visit_over3.pkl'\n",
    "with open(X_filePath, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Prepare the Word2Vec input\n",
    "corpus = []\n",
    "for subject_id, visits in data.items():\n",
    "    for hadm_id, features in visits.items():\n",
    "        currSequence = features['diagnoses'] + features['procedures'] + features['drugs']\n",
    "        corpus.append(currSequence)\n",
    "\n",
    "# check first few sequences\n",
    "print(\"Sample sequences for Word2Vec:\")\n",
    "\n",
    "for i in range(5):\n",
    "    print(corpus[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec model 만들기\n",
    "\n",
    "word2vec_model = Word2Vec(\n",
    "    sentences=corpus,  \n",
    "    vector_size=100, # standard baseline size = 100\n",
    "    window=5, # 그냥 일딴 5로 설정  \n",
    "    min_count=1, # 한번 나온것도 중요하지 않을까? 라는 생각\n",
    "    workers=4,         \n",
    "    sg=1 # Skip-gram model (use sg=0 for CBOW)\n",
    ")\n",
    "\n",
    "word2vec_model.save(\"single_w2v_embeddings.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 5145\n",
      "Embedding for d_572: [ 0.43213654 -0.07269233 -0.35849983  0.1171606  -0.10541403  0.42179534\n",
      " -0.3777496   0.00635634 -0.0681117   0.54373664 -0.16981858 -0.04998092\n",
      " -0.8013413   0.33431193  0.13255507 -0.07952484 -0.02630047 -0.67499405\n",
      " -0.1532572   0.46115348 -0.1299382   0.31279632 -0.20523222 -0.01393937\n",
      " -0.31712964  0.1607313   0.09532557 -0.10853101  0.674924   -0.6551267\n",
      "  0.13211031 -0.36103818  0.32552233  0.00238413 -0.05489227 -0.40951723\n",
      " -0.10167913 -0.12177955 -0.11126038 -0.44760582  0.41310793  0.41556662\n",
      "  0.13027777  0.29256997 -0.00574209 -0.2293887  -0.11028181 -0.632644\n",
      "  0.12453412 -0.05511767 -0.30835095 -0.18154167 -0.0109947  -0.5619737\n",
      "  0.02250702 -0.4615514  -0.2117955  -0.39175692 -0.38175717 -0.15047053\n",
      "  0.5094287   0.3981909  -0.9996721  -1.0411705   0.10332346  0.32288644\n",
      " -0.22617443 -0.09451224 -0.1693531  -0.38064343  0.14339     0.10654876\n",
      " -0.6787372   0.15967907  0.2724633  -0.05568499 -0.88747454  0.07161202\n",
      " -0.32878315  0.10173641  0.6209849   0.12400509  0.0057395   0.5802503\n",
      "  0.49411854  0.9429695  -0.5879115   1.0764768  -0.35419676 -0.40983582\n",
      " -0.43691325 -0.18568408  0.16217898  0.14135899  0.40492466  0.14363043\n",
      "  0.7967761   0.41681188 -0.3173243   0.04372895]\n",
      "Most similar diagnoses to d_572: [('d_456', 0.9529329538345337), ('d_571', 0.8743190169334412), ('d_452', 0.8597096800804138), ('d_537', 0.8533105254173279), ('d_286', 0.8485572338104248), ('d_260', 0.83585524559021), ('d_120', 0.8294060826301575), ('d_155', 0.7994128465652466), ('d_265', 0.7825607657432556), ('d_284', 0.7734653949737549)]\n"
     ]
    }
   ],
   "source": [
    "# check word2vec model\n",
    "\n",
    "word2vec_model = Word2Vec.load(\"single_w2v_embeddings.model\")\n",
    "\n",
    "print(\"Vocabulary size:\", len(word2vec_model.wv.index_to_key))\n",
    "\n",
    "diagnosis_embedding = word2vec_model.wv['d_572']\n",
    "print(\"Embedding for d_572:\", diagnosis_embedding)\n",
    "\n",
    "similar_diagnoses = word2vec_model.wv.most_similar('d_572')\n",
    "print(\"Most similar diagnoses to d_572:\", similar_diagnoses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
